{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8e4ea845-22d2-4f27-8521-c34e817d44ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "aa6955ca-a44d-4e87-a975-0301bc612118",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file has been saved as 'openbookqa_train.csv'\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "\n",
    "# Load the 'openbookqa' dataset (train split as an example)\n",
    "dataset = load_dataset(\"allenai/openbookqa\", split='train')\n",
    "\n",
    "# Convert to a Pandas DataFrame\n",
    "df = pd.DataFrame(dataset)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv('openbookqa_train.csv', index=False)\n",
    "\n",
    "print(\"CSV file has been saved as 'openbookqa_train.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fd3bc06d-8f5f-4537-a6ad-28f6a2f999ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('openbookqa_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "25f579ae-5af7-4107-bd9f-1d1be11fa3a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>question_stem</th>\n",
       "      <th>choices</th>\n",
       "      <th>answerKey</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7-980</td>\n",
       "      <td>The sun is responsible for</td>\n",
       "      <td>{'text': ['puppies learning new tricks', 'chil...</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7-584</td>\n",
       "      <td>When standing miles away from Mount Rushmore</td>\n",
       "      <td>{'text': ['the mountains seem very close', 'th...</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7-870</td>\n",
       "      <td>When food is reduced in the stomach</td>\n",
       "      <td>{'text': ['the mind needs time to digest', 'ta...</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7-321</td>\n",
       "      <td>Stars are</td>\n",
       "      <td>{'text': ['warm lights that float', 'made out ...</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9-732</td>\n",
       "      <td>You can make a telescope with a</td>\n",
       "      <td>{'text': ['straw', 'Glass', 'Candle', 'mailing...</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                 question_stem  \\\n",
       "0  7-980                    The sun is responsible for   \n",
       "1  7-584  When standing miles away from Mount Rushmore   \n",
       "2  7-870           When food is reduced in the stomach   \n",
       "3  7-321                                     Stars are   \n",
       "4  9-732               You can make a telescope with a   \n",
       "\n",
       "                                             choices answerKey  \n",
       "0  {'text': ['puppies learning new tricks', 'chil...         D  \n",
       "1  {'text': ['the mountains seem very close', 'th...         D  \n",
       "2  {'text': ['the mind needs time to digest', 'ta...         C  \n",
       "3  {'text': ['warm lights that float', 'made out ...         C  \n",
       "4  {'text': ['straw', 'Glass', 'Candle', 'mailing...         D  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5e1c794c-e64b-4eb8-9803-71325289568e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"{'text': ['the mountains seem very close', 'the mountains are boring', 'the mountains look the same as from up close', 'the mountains seem smaller than in photographs'], 'label': ['A', 'B', 'C', 'D']}\""
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['choices'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1d4af65e-40ca-4cc7-821e-a8be9120e25f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('modified_questions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a4ecba9a-ca25-4e65-ad1b-e23ce0839c2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question</th>\n",
       "      <th>Choices</th>\n",
       "      <th>Answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>When standing miles away from Mount Rushmore,</td>\n",
       "      <td>The mountains seem very close\\nThe mountains a...</td>\n",
       "      <td>The mountains seem smaller than in photographs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Question  \\\n",
       "0  When standing miles away from Mount Rushmore,   \n",
       "\n",
       "                                             Choices  \\\n",
       "0  The mountains seem very close\\nThe mountains a...   \n",
       "\n",
       "                                           Answer  \n",
       "0  The mountains seem smaller than in photographs  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "606abc82-1f3b-4ea9-bfd2-fa061bc0a390",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The mountains seem very close\\nThe mountains are boring\\nThe mountains look the same as from up close\\nThe mountains seem smaller than in photographs'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Choices'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3845d636-dd9d-4160-8837-05d38f7ca44b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file 'modified_full_dataset.csv' has been created successfully.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset from Hugging Face (or a CSV file if you have it locally)\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Load the 'openbookqa' dataset (assuming we're modifying the train split for example)\n",
    "dataset = load_dataset(\"allenai/openbookqa\", split='train')\n",
    "\n",
    "# Convert to a Pandas DataFrame\n",
    "df = pd.DataFrame(dataset)\n",
    "\n",
    "# Function to convert choices dictionary into the desired format\n",
    "def format_choices(row):\n",
    "    return \"\\n\".join(row['choices']['text'])\n",
    "\n",
    "# Apply the function to all rows to format the 'choices' column\n",
    "df['choices'] = df.apply(format_choices, axis=1)\n",
    "\n",
    "# Replace the answerKey column with the full text answer for each row\n",
    "df['answerKey'] = df.apply(lambda row: row['choices'].split(\"\\n\")[ord(row['answerKey']) - ord('A')], axis=1)\n",
    "\n",
    "# Rename columns for better understanding\n",
    "df.rename(columns={'question_stem': 'Question', 'choices': 'Choices', 'answerKey': 'Answer'}, inplace=True)\n",
    "\n",
    "# Save the modified dataset to a new CSV file\n",
    "df.to_csv('modified_full_dataset.csv', index=False)\n",
    "\n",
    "print(\"CSV file 'modified_full_dataset.csv' has been created successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4d913ed5-d56c-4a33-a91d-9bb2762f9b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('modified_full_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f462ad3c-b3a8-492f-9d8f-a55e929a8415",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Question</th>\n",
       "      <th>Choices</th>\n",
       "      <th>Answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7-980</td>\n",
       "      <td>The sun is responsible for</td>\n",
       "      <td>puppies learning new tricks\\nchildren growing ...</td>\n",
       "      <td>plants sprouting, blooming and wilting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7-584</td>\n",
       "      <td>When standing miles away from Mount Rushmore</td>\n",
       "      <td>the mountains seem very close\\nthe mountains a...</td>\n",
       "      <td>the mountains seem smaller than in photographs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7-870</td>\n",
       "      <td>When food is reduced in the stomach</td>\n",
       "      <td>the mind needs time to digest\\ntake a second t...</td>\n",
       "      <td>nutrients are being deconstructed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7-321</td>\n",
       "      <td>Stars are</td>\n",
       "      <td>warm lights that float\\nmade out of nitrate\\ng...</td>\n",
       "      <td>great balls of gas burning billions of miles away</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9-732</td>\n",
       "      <td>You can make a telescope with a</td>\n",
       "      <td>straw\\nGlass\\nCandle\\nmailing tube</td>\n",
       "      <td>mailing tube</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                      Question  \\\n",
       "0  7-980                    The sun is responsible for   \n",
       "1  7-584  When standing miles away from Mount Rushmore   \n",
       "2  7-870           When food is reduced in the stomach   \n",
       "3  7-321                                     Stars are   \n",
       "4  9-732               You can make a telescope with a   \n",
       "\n",
       "                                             Choices  \\\n",
       "0  puppies learning new tricks\\nchildren growing ...   \n",
       "1  the mountains seem very close\\nthe mountains a...   \n",
       "2  the mind needs time to digest\\ntake a second t...   \n",
       "3  warm lights that float\\nmade out of nitrate\\ng...   \n",
       "4                 straw\\nGlass\\nCandle\\nmailing tube   \n",
       "\n",
       "                                              Answer  \n",
       "0             plants sprouting, blooming and wilting  \n",
       "1     the mountains seem smaller than in photographs  \n",
       "2                  nutrients are being deconstructed  \n",
       "3  great balls of gas burning billions of miles away  \n",
       "4                                       mailing tube  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "09920855-cfc4-4982-a712-cf94570d5fc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: mailing tube\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Load the CSV file\n",
    "data = pd.read_csv('modified_full_dataset.csv')\n",
    "\n",
    "# Function to calculate the most similar question\n",
    "def find_most_similar_question(input_question, data):\n",
    "    # Extract the questions from the CSV file\n",
    "    questions = data['Question']\n",
    "    \n",
    "    # Concatenate the input question to the series of existing questions\n",
    "    all_questions = pd.concat([questions, pd.Series([input_question])], ignore_index=True)\n",
    "    \n",
    "    # Vectorize the questions and the input question using TF-IDF\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    vectors = vectorizer.fit_transform(all_questions)\n",
    "    \n",
    "    # Calculate cosine similarity between input question and all stored questions\n",
    "    cosine_sim = cosine_similarity(vectors[-1], vectors[:-1])\n",
    "    \n",
    "    # Get the index of the most similar question\n",
    "    most_similar_idx = cosine_sim.argmax()\n",
    "    \n",
    "    # Return the corresponding answer from the CSV\n",
    "    return data.iloc[most_similar_idx]['Answer']\n",
    "\n",
    "# Example usage\n",
    "input_question = \"telescope can be made with\"\n",
    "answer = find_most_similar_question(input_question, data)\n",
    "print(f\"Answer: {answer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c6eecb-ea86-4e5b-b285-36d8dfbfcce5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d76fee8a-6eae-41e2-8443-fce095b6bdb4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
